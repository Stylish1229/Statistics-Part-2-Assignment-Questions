{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is hypothesis testing in statistics ?\n",
        "- Hypothesis testing is a method used in statistics to check whether an assumption about a population is true or not based on sample data."
      ],
      "metadata": {
        "id": "4PUFtQo4D0Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis ?\n",
        "- Null hypothesis (H‚ÇÄ) assumes no effect or no difference.\n",
        "Alternative hypothesis (H‚ÇÅ) suggests there is an effect or difference."
      ],
      "metadata": {
        "id": "ofa1OiESEZ3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the significance level in hypothesis testing, and why is it important?\n",
        "- Significance level (Œ±) :  is the threshold for deciding whether to reject the null hypothesis.  \n",
        "It's important because it controls the chance of making a wrong decision (false positive)."
      ],
      "metadata": {
        "id": "UU0i-v1NEuTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  What does a P-value represent in hypothesis testing ?\n",
        "- The P-value  shows the probability of getting the observed results **if the null hypothesis is true .  \n",
        "It helps decide whether to reject the null hypothesis."
      ],
      "metadata": {
        "id": "MQEzrjftE8Ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do you interpret the P-value in hypothesis testing ?\n",
        "- The P-value tells you how unlikely your data is, assuming the null hypothesis is true.\n",
        "\n",
        "- If the P-value is small (like 0.05 or less), you can reject the null hypothesis. This means you have enough evidence to say that what you're testing (like a treatment effect) could be true.\n",
        "\n",
        "- If the P-value is large (greater than 0.05), you cannot reject the null hypothesis. This means you don't have enough evidence to say that what you're testing is true."
      ],
      "metadata": {
        "id": "-Om_-2t9FNTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What are Type 1 and Type 2 errors in hypothesis testing ?\n",
        "- In hypothesis testing, there are two types of errors that can occur when making decisions about the null hypothesis:\n",
        "- Type 1 Error (False Positive):\n",
        "What happens? You reject the null hypothesis when it's actually true.\n",
        "- Example: You think a new drug works, but it actually doesn‚Äôt. You made a false claim.\n",
        "- Risk: Denoted by Œ± (alpha), usually 5% (0.05).\n",
        "-Type 2 Error: what happens? You fail to reject the null hypothesis when it's actually false.\n",
        "Example: You think a new drug doesn‚Äôt work, but it actually does. You missed the truth.\n",
        "Risk: Denoted by Œ≤ (beta)."
      ],
      "metadata": {
        "id": "m4SJcyFXFohl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing ?\n",
        "- One-Tailed Test: Tests for an effect in only one direction (either greater or lesser).\n",
        "- Two-Tailed Test: Tests for an effect in both directions (either greater or lesser).\n",
        "- Use a one-tailed test if you're sure the effect is in one direction; use a two-tailed test if you're open to effects in either direction."
      ],
      "metadata": {
        "id": "ciai4p-TGqBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  What is the Z-test, and when is it used in hypothesis testing ?\n",
        "- The Z-test is used to test if there's a significant difference between a sample mean and a population mean (or between two sample means), assuming:\n",
        "Large sample size (n > 30) Known population standard deviation\n",
        "- Data is normally distributed"
      ],
      "metadata": {
        "id": "i15KOerZHIhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  How do you calculate the Z-score, and what does it represent in hypothesis testing ?\n",
        "- The Z-score is calculated as X-Œº/œÉ where ùëã s the data point Œº is the mean,and œÉ is the standard deviation. It shows how many standard deviations a value is from the mean and helps assess statistical significance in hypothesis testing.\n",
        "\n"
      ],
      "metadata": {
        "id": "nsjI3GbJITYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the T-distribution, and when should it be used instead of the normal distribution ?\n",
        "- The T-distribution is used instead of the normal distribution when the sample size is small (n < 30) and the population standard deviation is unknown. It is wider and has heavier tails, which gives more accurate results for small samples."
      ],
      "metadata": {
        "id": "Kg6ds_QPJL0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is the difference between a Z-test and a T-test ?\n",
        "- Z-test vs T-test :\n",
        "- Z-test: Used when sample size is large (n > 30) and population standard deviation is known.\n",
        "- T-test: Used when sample size is small (n < 30) and population standard deviation is unknown."
      ],
      "metadata": {
        "id": "bmN_15AwJbjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the T-test, and how is it used in hypothesis testing ?\n",
        "- The T-test is a statistical test used to compare means when the sample size is small and the population standard deviation is unknown.\n",
        "- Usage in hypothesis testing:\n",
        "It checks if the sample mean is significantly different from the population mean or another sample mean.\n",
        "Common types:\n",
        "- One-sample T-test (sample vs population)\n",
        "- Two-sample T-test (comparing two groups)\n",
        "- Paired T-test (before & after data)\n",
        "- It helps decide whether to reject the null hypothesis."
      ],
      "metadata": {
        "id": "T2WWHH_HJx4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is the relationship between Z-test and T-test in hypothesis testing ?\n",
        "- Relationship between Z-test and T-test : Both are used to compare means in hypothesis testing.\n",
        "\n",
        "Both calculate a test statistic to decide if the result is statistically significant.\n",
        "\n",
        "The T-test is a generalization of the Z-test used when the sample size is small and population standard deviation is unknown.\n",
        "\n",
        "As the sample size increases, the T-distribution approaches the Z-distribution."
      ],
      "metadata": {
        "id": "v7NoaU86KTXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is a confidence interval, and how is it used to interpret statistical results ?\n",
        "- A confidence interval (CI) is a range of values that likely contains the true population parameter (like the mean) with a certain level of confidence (e.g., 95%).\n",
        "- It helps you understand the uncertainty in your estimate.\n",
        "- If the CI doesn't include the null value (like 0 or no difference), the result is statistically significant."
      ],
      "metadata": {
        "id": "SXp1tW3yKr8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  What is the margin of error, and how does it affect the confidence interval ?\n",
        "- The margin of error is the amount added and subtracted from a sample estimate to create a confidence interval.\n",
        "- A larger margin of error makes the confidence interval wider (less precise).\n",
        "- A smaller margin of error makes it narrower (more precise).\n",
        "- It depends on sample size, confidence level, and variability."
      ],
      "metadata": {
        "id": "GsVR7RbfLTYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How is Bayes' Theorem used in statistics, and what is its significance ?\n",
        "- Bayes' Theorem is used to update the probability of an event based on new evidence.\n",
        "- It helps in revising predictions or beliefs using prior knowledge and new data.\n",
        "- It's widely used in medical testing, spam filtering, and machine learning to improve decision-making.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m0y68iG_Ljo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is the Chi-square distribution, and when is it used ?\n",
        "- The Chi-square distribution is used to test relationships between categorical variables.\n",
        "- It‚Äôs used in Chi-square tests like:\n",
        "\n",
        "Goodness-of-fit test (if data fits a distribution)\n",
        "\n",
        "Test of independence (if two variables are related)\n",
        "\n",
        "It applies when data is in frequency (count) form."
      ],
      "metadata": {
        "id": "Ms6qYdknL74b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the Chi-square goodness of fit test, and how is it applied ?\n",
        "- The Chi-square goodness of fit test checks if observed data matches an expected distribution.\n",
        "- It compares observed vs. expected frequencies in categories.\n",
        "If the difference is large, it suggests the data doesn't fit the expected distribution.\n",
        "Used for categorical data like dice rolls, survey responses, etc."
      ],
      "metadata": {
        "id": "CK2NKZ0RMZos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What is the F-distribution, and when is it used in hypothesis testing ?\n",
        "- The F-distribution is used to compare variances between two groups.\n",
        "- It's mainly used in ANOVA (Analysis of Variance) to test if three or more group means are significantly different.\n",
        "Also used to compare two variances in F-tests."
      ],
      "metadata": {
        "id": "v2WkcgVqMnq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is an ANOVA test, and what are its assumptions ?\n",
        "- An ANOVA (Analysis of Variance) test is used to compare the means of three or more groups to see if there are statistically significant differences between them.\n",
        "- Assumptions of ANOVA:\n",
        "- Independence: The samples are independent of each other.\n",
        "- Normality: The data in each group is approximately normally distributed.\n",
        "-Homogeneity of variances: The variances across groups are equal (also known as homoscedasticity).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5PUrUqJjM2r8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.  What are the different types of ANOVA tests ?\n",
        "- There are several types of ANOVA tests, depending on the number of factors and levels being tested:\n",
        "- One-Way ANOVA:\n",
        "- Used to compare means across three or more independent groups based on one factor.\n",
        "- Example: Comparing the test scores of students from three different teaching methods.\n",
        "- Two-Way ANOVA:\n",
        "- Used to compare means across two independent factors (with or without interaction).\n",
        "- Example: Comparing test scores based on both teaching method and gender.\n",
        "- Repeated Measures ANOVA:\n",
        "Used when the same subjects are tested multiple times under different conditions.\n",
        "- Example: Measuring blood pressure at multiple time points after administering a drug.\n",
        "- Multivariate Analysis of Variance (MANOVA):\n",
        "An extension of ANOVA used to test the effect of one or more independent variables on multiple dependent variables.\n",
        "- Example: Comparing the effect of a drug on multiple health outcomes (e.g., blood pressure, heart rate).\n",
        "These tests allow you to analyze the variance between groups and make inferences about the factors influencing the data."
      ],
      "metadata": {
        "id": "WhlD1jlsNMsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "- The F-test is used to compare variances between two or more groups to determine if they are significantly different.\n",
        "- It helps test the null hypothesis that two populations have the same variance.\n",
        "- Used in ANOVA to compare multiple group means (by comparing their variances).\n",
        "- Also used to test regression models for overall significance.\n",
        "\n",
        "- The F-statistic is the ratio of between-group variance to within-group variance. If the F-statistic is large, it suggests that the group means are significantly different."
      ],
      "metadata": {
        "id": "K32RPjYHN0kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "# interpret the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def z_test(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    # Calculate sample mean and sample size\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Calculate the Z statistic\n",
        "    z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Calculate the p-value\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))  # Two-tailed test\n",
        "\n",
        "    # Determine the critical value for the given alpha level\n",
        "    critical_value = stats.norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Sample Mean: {sample_mean}\")\n",
        "    print(f\"Population Mean: {population_mean}\")\n",
        "    print(f\"Z Statistic: {z_statistic}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "    print(f\"Critical Value (alpha={alpha}): ¬±{critical_value}\")\n",
        "\n",
        "    # Interpret the results\n",
        "    if abs(z_statistic) > critical_value:\n",
        "        print(\"Reject the null hypothesis: There is a significant difference between the sample mean and the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: There is no significant difference between the sample mean and the population mean.\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample data\n",
        "    sample_data = [20, 22, 21, 19, 23, 20, 22, 21, 20, 19]\n",
        "\n",
        "    # Known population parameters\n",
        "    population_mean = 21\n",
        "    population_std = 2  # Known population standard deviation\n",
        "\n",
        "    # Perform Z-test\n",
        "    z_test(sample_data, population_mean, population_std)"
      ],
      "metadata": {
        "id": "in8Hvj7XOr3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def simulate_data(sample_size, true_mean, true_std):\n",
        "    \"\"\"Simulate random data from a normal distribution.\"\"\"\n",
        "    return np.random.normal(loc=true_mean, scale=true_std, size=sample_size)\n",
        "\n",
        "def perform_t_test(sample_data, population_mean):\n",
        "    \"\"\"Perform a one-sample t-test and return the t-statistic and p-value.\"\"\"\n",
        "    t_statistic, p_value = stats.ttest_1samp(sample_data, population_mean)\n",
        "    return t_statistic, p_value\n",
        "\n",
        "def main():\n",
        "    # Parameters for simulation\n",
        "    sample_size = 30\n",
        "    true_mean = 100\n",
        "    true_std = 15\n",
        "    population_mean = 100  # Null hypothesis mean\n",
        "\n",
        "    # Simulate random data\n",
        "    sample_data = simulate_data(sample_size, true_mean, true_std)\n",
        "\n",
        "    # Perform t-test\n",
        "    t_statistic, p_value = perform_t_test(sample_data, population_mean)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Sample Mean: {np.mean(sample_data)}\")\n",
        "    print(f\"T-Statistic: {t_statistic}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "\n",
        "    # Interpret the results\n",
        "    alpha = 0.05\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: There is a significant difference from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: There is no significant difference from the population mean.\")\n",
        "\n",
        "    # Optional: Visualize the sample data\n",
        "    plt.hist(sample_data, bins=10, alpha=0.7, color='blue', edgecolor='black')\n",
        "    plt.axvline(population_mean, color='red', linestyle='dashed', linewidth=1)\n",
        "    plt.title('Histogram of Sample Data')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "rrolkbU6PRAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Given data\n",
        "sample_mean = 50  # Sample mean\n",
        "population_mean = 55  # Population mean\n",
        "population_std_dev = 10  # Population standard deviation\n",
        "sample_size = 30  # Sample size\n",
        "\n",
        "# Z-test calculation\n",
        "z_score = (sample_mean - population_mean) / (population_std_dev / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate p-value\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # two-tailed test\n",
        "\n",
        "# Output results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Decision making\n",
        "alpha = 0.05  # significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
      ],
      "metadata": {
        "id": "zsj9jwfpPjxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Given data\n",
        "sample_mean = 50  # Sample mean\n",
        "population_mean = 55  # Population mean\n",
        "population_std_dev = 10  # Population standard deviation\n",
        "sample_size = 30  # Sample size\n",
        "\n",
        "# Z-test calculation\n",
        "z_score = (sample_mean - population_mean) / (population_std_dev / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate p-value (two-tailed)\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # two-tailed test\n",
        "\n",
        "# Output results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Decision making\n",
        "alpha = 0.05  # significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the\n"
      ],
      "metadata": {
        "id": "xhVIKiyAP2A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.  Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_type_errors(sample_mean, population_mean, population_std_dev, sample_size, alpha=0.05):\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std_dev / np.sqrt(sample_size))\n",
        "\n",
        "    # Critical value for two-tailed test\n",
        "    critical_value = stats.norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    # Type 1 Error (Œ±) - Area in the rejection regions (tails)\n",
        "    type_1_error = 2 * (1 - stats.norm.cdf(critical_value))  # Two-tailed\n",
        "\n",
        "    # Type 2 Error (Œ≤) - Area in the non-rejection region when the alternative hypothesis is true\n",
        "    # Assume the true mean is shifted by a small effect size\n",
        "    effect_size = 2  # Assume an effect size (shift in the mean)\n",
        "    shifted_mean = population_mean + effect_size\n",
        "    z_beta = (critical_value - (shifted_mean - population_mean)) / (population_std_dev / np.sqrt(sample_size))\n",
        "    type_2_error = stats.norm.cdf(critical_value - z_beta)  # Area in the non-rejection region\n",
        "\n",
        "    print(f\"Z-score: {z_score}\")\n",
        "    print(f\"Type 1 Error (Œ±): {type_1_error}\")\n",
        "    print(f\"Type 2 Error (Œ≤): {type_2_error}\")\n",
        "\n",
        "    # Visualization: Plotting the normal distribution and error regions\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = stats.norm.pdf(x, 0, 1)  # Standard normal distribution\n",
        "\n",
        "    # Plot the normal distribution\n",
        "    plt.plot(x, y, label=\"Normal Distribution\", color='blue')\n",
        "\n",
        "    # Highlight the rejection regions for Type 1 Error\n",
        "    plt.fill_between(x, 0, y, where=(x <= -critical_value), color='red', alpha=0.5, label=\"Rejection Region (Type 1 Error)\")\n",
        "    plt.fill_between(x, 0, y, where=(x >= critical_value), color='red', alpha=0.5)\n",
        "\n",
        "    # Highlight the Type 2 Error region (non-rejection region where we fail to reject the null)\n",
        "    plt.fill_between(x, 0, y, where=(x >= critical_value - z_beta) & (x <= critical_value), color='yellow', alpha=0.5, label=\"Type 2 Error (Œ≤)\")\n",
        "\n",
        "    # Mark the Z-score on the plot\n",
        "    plt.axvline(z_score, color='green', linestyle='dashed', label=f\"Z-score = {z_score:.2f}\")\n",
        "\n",
        "    # Add labels and legend\n",
        "    plt.title(\"Type 1 and Type 2 Errors in Hypothesis Testing\")\n",
        "    plt.xlabel(\"Z-value\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.legend(loc='upper left')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "sample_mean = 50  # Sample mean\n",
        "population_mean = 55  # Population mean\n",
        "population_std_dev = 10  # Population standard deviation\n",
        "sample_size = 30  # Sample size\n",
        "\n",
        "visualize_type_errors(sample_mean, population_mean, population_std_dev, sample_size)\n"
      ],
      "metadata": {
        "id": "3AiCHsKDQDzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Write a Python program to perform an independent T-test and interpret the results ?\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Sample data for two independent groups\n",
        "group1 = [23, 21, 19, 25, 27, 22, 20, 24, 19, 22]\n",
        "group2 = [30, 32, 31, 35, 33, 34, 30, 29, 36, 32]\n",
        "\n",
        "# Perform independent T-test\n",
        "t_stat, p_value = stats.ttest_ind(group1, group2)\n",
        "\n",
        "# Output results\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation of results\n",
        "alpha = 0.05  # Significance level (commonly used is 0.05)\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The means of the two groups are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The means of the two groups are not significantly different.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0iVE8JZXRB38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.  Perform a paired sample T-test using Python and visualize the comparison results ?\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for two related groups (before and after treatment)\n",
        "before_treatment = [50, 55, 60, 65, 70, 75, 80, 85, 90, 95]\n",
        "after_treatment = [52, 56, 63, 67, 71, 78, 82, 87, 93, 98]\n",
        "\n",
        "# Perform paired sample T-test\n",
        "t_stat, p_value = stats.ttest_rel(before_treatment, after_treatment)\n",
        "\n",
        "# Output results\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation of results\n",
        "alpha = 0.05  # Significance level\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between before and after treatment.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between before and after treatment.\")\n",
        "\n",
        "# Visualization: Comparing before and after treatment\n",
        "x = np.arange(len(before_treatment))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plotting the before and after treatment data\n",
        "plt.plot(x, before_treatment, label='Before Treatment', marker='o', linestyle='--', color='blue')\n",
        "plt.plot(x, after_treatment, label='After Treatment', marker='o', linestyle='-', color='green')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.title('Comparison of Before and After Treatment')\n",
        "plt.xlabel('Subjects')\n",
        "plt.ylabel('Scores')\n",
        "plt.xticks(x)\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xBgjLjlCRSaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.  Simulate data and perform both Z-test and T-test, then compare the results using Python ?\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulate data for the sample (Assume population mean = 50, population std deviation = 10, sample size = 30)\n",
        "population_mean = 50\n",
        "population_std_dev = 10\n",
        "sample_size = 30\n",
        "\n",
        "# Generate a sample of data\n",
        "sample_data = np.random.normal(loc=population_mean, scale=population_std_dev, size=sample_size)\n",
        "\n",
        "# Calculate sample mean and sample standard deviation\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_std_dev = np.std(sample_data, ddof=1)\n",
        "\n",
        "# Z-test calculation (Assuming known population standard deviation)\n",
        "z_score = (sample_mean - population_mean) / (population_std_dev / np.sqrt(sample_size))\n",
        "z_p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "\n",
        "# T-test calculation (Using sample standard deviation)\n",
        "t_stat, t_p_value = stats.ttest_1samp(sample_data, population_mean)\n",
        "\n",
        "# Output results\n",
        "print(f\"Z-test result:\")\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {z_p_value}\")\n",
        "print(\"\\nT-test result:\")\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {t_p_value}\")\n",
        "\n",
        "# Interpretation of results\n",
        "alpha = 0.05  # Significance level\n",
        "\n",
        "# Z-test interpretation\n",
        "if z_p_value < alpha:\n",
        "    print(\"Z-test: Reject the null hypothesis - The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Z-test: Fail to reject the null hypothesis - The sample mean is not significantly different from the population mean.\")\n",
        "\n",
        "# T-test interpretation\n",
        "if t_p_value < alpha:\n",
        "    print(\"T-test: Reject the null hypothesis - The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"T-test: Fail to reject the null hypothesis - The sample mean is not significantly different from the population mean.\")\n",
        "\n",
        "# Visualization: Comparing the sample mean, population mean, and Z-test and T-test results\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot sample data distribution\n",
        "plt.hist(sample_data, bins=10, alpha=0.7, color='blue', label=\"Sample Data\")\n",
        "\n",
        "# Plot population mean\n",
        "plt.axvline(population_mean, color='green', linestyle='dashed', linewidth=2, label=\"Population Mean\")\n",
        "\n",
        "# Plot sample mean\n",
        "plt.axvline(sample_mean, color='red', linestyle='solid', linewidth=2, label=\"Sample Mean\")\n",
        "\n",
        "# Add labels and legend\n",
        "plt.title(\"Comparison of Sample Data with Population Mean\")\n",
        "plt.xlabel(\"Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Oz7cqHJpRkAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Write a Python function to calculate the confidence interval for a sample mean and explain its significance ?\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def calculate_confidence_interval(sample_data, confidence_level=0.95):\n",
        "    # Calculate sample mean and standard deviation\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_std_dev = np.std(sample_data, ddof=1)  # Using ddof=1 for sample standard deviation\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Z-score for the given confidence level (use t-distribution for small sample size)\n",
        "    alpha = 1 - confidence_level\n",
        "    t_score = stats.t.ppf(1 - alpha / 2, df=sample_size - 1)  # T-distribution for confidence interval\n",
        "\n",
        "    # Standard error of the mean\n",
        "    standard_error = sample_std_dev / np.sqrt(sample_size)\n",
        "\n",
        "    # Margin of error\n",
        "    margin_of_error = t_score * standard_error\n",
        "\n",
        "    # Confidence interval\n",
        "    confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
        "\n",
        "    return sample_mean, confidence_interval\n",
        "\n",
        "# Example usage\n",
        "sample_data = [23, 21, 19, 25, 27, 22, 20, 24, 19, 22]  # Sample data\n",
        "confidence_level = 0.95  # 95% confidence level\n",
        "\n",
        "sample_mean, confidence_interval = calculate_confidence_interval(sample_data, confidence_level)\n",
        "\n",
        "# Output results\n",
        "print(f\"Sample Mean: {sample_mean}\")\n",
        "print(f\"{int(confidence_level * 100)}% Confidence Interval: {confidence_interval}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Y_Q6okThR3T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Write a Python program to calculate the margin of error for a given confidence level using sample data ?\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def calculate_margin_of_error(sample_data, confidence_level=0.95):\n",
        "    # Calculate sample standard deviation and size\n",
        "    sample_std_dev = np.std(sample_data, ddof=1)  # Sample standard deviation (using ddof=1)\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Calculate the standard error of the mean\n",
        "    standard_error = sample_std_dev / np.sqrt(sample_size)\n",
        "\n",
        "    # Calculate the Z or T score based on the sample size\n",
        "    alpha = 1 - confidence_level  # Significance level (alpha)\n",
        "\n",
        "    if sample_size < 30:  # Use T-distribution for small sample sizes (n < 30)\n",
        "        t_score = stats.t.ppf(1 - alpha / 2, df=sample_size - 1)  # T-distribution\n",
        "    else:  # Use Z-distribution for larger sample sizes\n",
        "        t_score = stats.norm.ppf(1 - alpha / 2)  # Z-distribution (normal)\n",
        "\n",
        "    # Margin of error calculation\n",
        "    margin_of_error = t_score * standard_error\n",
        "\n",
        "    return margin_of_error\n",
        "\n",
        "# Example usage\n",
        "sample_data = [23, 21, 19, 25, 27, 22, 20, 24, 19, 22]  # Sample data\n",
        "confidence_level = 0.95  # 95% confidence level\n",
        "\n",
        "margin_of_error = calculate_margin_of_error(sample_data, confidence_level)\n",
        "\n",
        "# Output result\n",
        "print(f\"Margin of Error for {int(confidence_level * 100)}% confidence level: {margin_of_error:.4f}\")\n"
      ],
      "metadata": {
        "id": "-ml1sNI8SGi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process ?\n",
        "def bayesian_inference(prior, likelihood, false_positive, total_positive):\n",
        "    \"\"\"\n",
        "    Calculate the posterior probability using Bayes' Theorem.\n",
        "\n",
        "    Args:\n",
        "    prior (float): Prior probability of having the disease (P(A))\n",
        "    likelihood (float): Likelihood of a positive test given the disease (P(B|A))\n",
        "    false_positive (float): Probability of a positive test given no disease (P(B|¬¨A))\n",
        "    total_positive (float): Probability of a positive test result (P(B))\n",
        "\n",
        "    Returns:\n",
        "    float: Posterior probability of having the disease given a positive test (P(A|B))\n",
        "    \"\"\"\n",
        "    # Calculate the total probability of a positive test result (P(B))\n",
        "    total_probability = (likelihood * prior) + (false_positive * (1 - prior))\n",
        "\n",
        "    # Apply Bayes' Theorem to calculate the posterior (P(A|B))\n",
        "    posterior = (likelihood * prior) / total_probability\n",
        "    return posterior\n",
        "\n",
        "# Example data for the problem\n",
        "prior = 0.01  # Prior probability of having the disease (1% in the population)\n",
        "likelihood = 0.95  # Likelihood of a positive test given disease (95% true positive rate)\n",
        "false_positive = 0.05  # False positive rate (5% false positive rate)\n",
        "total_positive = (likelihood * prior) + (false_positive * (1 - prior))  # Total probability of a positive test\n",
        "\n",
        "# Perform Bayesian Inference\n",
        "posterior = bayesian_inference(prior, likelihood, false_positive, total_positive)\n",
        "\n",
        "print(f\"The probability of having the disease given a positive test result (P(A|B)) is: {posterior:.4f}\")\n"
      ],
      "metadata": {
        "id": "UG3eeKz3SU1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Perform a Chi-square test for independence between two categorical variables in Python ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Create the contingency table (observed frequencies)\n",
        "observed = np.array([[30, 10], [20, 40]])\n",
        "\n",
        "# Perform the Chi-square test for independence\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(observed)\n",
        "\n",
        "# Output the results\n",
        "print(f\"Chi-square statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"Expected frequencies:\\n{expected}\")\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05  # 5% significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The two variables are not independent.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The two variables are independent.\")\n"
      ],
      "metadata": {
        "id": "GZxL2CMtS0T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13.Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create the contingency table (observed frequencies)\n",
        "observed = np.array([[30, 10], [20, 40]])\n",
        "\n",
        "# Calculate the row totals, column totals, and grand total\n",
        "row_totals = observed.sum(axis=1)  # Sum across rows\n",
        "column_totals = observed.sum(axis=0)  # Sum across columns\n",
        "grand_total = observed.sum()  # Sum of all entries\n",
        "\n",
        "# Calculate expected frequencies for each cell\n",
        "expected = np.outer(row_totals, column_totals) / grand_total\n",
        "\n",
        "# Output the observed and expected frequencies\n",
        "print(\"Observed frequencies:\")\n",
        "print(observed)\n",
        "print(\"\\nExpected frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "LNCW-ab5TI2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Observed data (frequencies of the outcomes of a die roll)\n",
        "observed = np.array([12, 10, 8, 9, 11, 10])\n",
        "\n",
        "# Expected data (for a fair die, each outcome is expected 10 times out of 60 rolls)\n",
        "expected = np.array([10, 10, 10, 10, 10, 10])\n",
        "\n",
        "# Perform the Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = stats.chisquare(observed, expected)\n",
        "\n",
        "# Output the results\n",
        "print(f\"Chi-square statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RYQdHPBOYWXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15. Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics ?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Set up the parameters for the Chi-square distribution\n",
        "df_values = [1, 2, 5, 10]  # Different degrees of freedom\n",
        "x = np.linspace(0, 30, 1000)  # X-axis values (range for the distribution)\n",
        "\n",
        "# Plot the Chi-square distribution for different degrees of freedom\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for df in df_values:\n",
        "    # Calculate the Chi-square distribution PDF for each df\n",
        "    y = stats.chi2.pdf(x, df)\n",
        "    plt.plot(x, y, label=f'df={df}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Chi-square Distribution for Different Degrees of Freedom\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend(title=\"Degrees of Freedom\")\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tYtO3NRYYd6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16.  Implement an F-test using Python to compare the variances of two random samples ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulate two random samples\n",
        "sample1 = np.random.normal(loc=0, scale=np.sqrt(10), size=50)  # Variance = 10\n",
        "sample2 = np.random.normal(loc=0, scale=np.sqrt(15), size=50)  # Variance = 15\n",
        "\n",
        "# Calculate the variances of the two samples\n",
        "var1 = np.var(sample1, ddof=1)  # Sample variance with Bessel's correction\n",
        "var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "# Calculate the F-statistic: ratio of the variances\n",
        "F_stat = var1 / var2 if var1 > var2 else var2 / var_\n"
      ],
      "metadata": {
        "id": "TqkB42fUYxRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate plant growth data for 3 fertilizers (A, B, and C)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Data for each group (Fertilizer A, B, and C)\n",
        "fertilizer_A = np.random.normal(loc=20, scale=5, size=30)  # Mean = 20, SD = 5\n",
        "fertilizer_B = np.random.normal(loc=22, scale=5, size=30)  # Mean = 22, SD = 5\n",
        "fertilizer_C = np.random.normal(loc=25, scale=5, size=30)  # Mean = 25_\n"
      ],
      "metadata": {
        "id": "d9WyoTfqY6yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18. import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate data for 3 different diet groups (A, B, and C)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Data for each group (Diet A, Diet B, Diet C)\n",
        "diet_A = np.random.normal(loc=60, scale=10, size=30)  # Mean = 60, SD = 10\n",
        "diet\n"
      ],
      "metadata": {
        "id": "QmT70vvpZFnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19. import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def check_anova_assumptions(*groups):\n",
        "    # Check normality for each group using the Shapiro-Wilk test\n",
        "    print(\"Normality Tests (Shapiro-Wilk Test):\")\n",
        "    for i, group in enumerate(groups, 1):\n",
        "        stat, p_value = stats.shapiro(group)\n",
        "        print(f\"Group {i}: Shapiro-Wilk Test p-value = {p_value:.4f}\")\n",
        "        if p_value < 0.05:\n",
        "            print(f\"Group {i} does not follow a normal distribution.\\n\")\n",
        "        else:\n",
        "            print(f\"Group\n"
      ],
      "metadata": {
        "id": "p331g4QDZNPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20. import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "# Simulate the data for the experiment\n",
        "np.random.seed(42)\n",
        "\n",
        "# Two factors: Fertilizer (A, B) and Watering Frequency (Daily, Weekly)\n",
        "fertilizer = ['A', 'B']\n",
        "watering_frequency = ['Daily', 'Weekly']\n",
        "\n",
        "# Randomly generate data for each combination of the two factors\n",
        "data = {\n",
        "    'Fertilizer': np.repeat(fertilizer, 2 * 30*\n"
      ],
      "metadata": {
        "id": "gvkJCdzKZT59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21. import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "def plot_f_distribution(d1, d2, size=1000):\n",
        "    # Generate random F-distribution data\n",
        "    data = np.random.f(d1, d2, size)\n",
        "\n",
        "    # Plot the F-distribution\n",
        "    x = np.linspace(0, np.max(data), 1000)\n",
        "    pdf = stats.f.pdf(x, d1, d2)  # Probability density function\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, pdf, label=f'F-distribution (d1={d1}, d2={d2})', color='blue')\n",
        "    plt.fill_between(x, 0, pdf, alpha=0.3, color='blue')\n",
        "    plt.title(f'F-distribution (d1={d1}, d2={d2})\n"
      ],
      "metadata": {
        "id": "SeANkQ48ZbF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate the data for three groups\n",
        "np.random.seed(42)\n",
        "\n",
        "# Group A, B, C data (simulating sample data from normal distributions)\n",
        "group_A = np.random.normal(loc=20, scale=5, size=30)  # Mean = 20, SD = 5\n",
        "group_B = np.random.normal(loc=22, scale=5, size=30)  # Mean = 22, SD = 5\n",
        "group_C = np.random.normal(loc=25, scale=5, size=30)  # Mean = 25, SD = 5\n",
        "\n",
        "# Perform One-Way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(group_A, group_B, group_C)\n",
        "\n",
        "# Output the results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation of the ANOVA results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: There is a significant difference between group means.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: There is no significant difference between group means.\")\n",
        "\n",
        "# Visualize the group means with boxplots\n",
        "data = [group_A, group_B, group_C]\n",
        "group_labels = ['Group A', 'Group B', 'Group C']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=data, labels=group_labels, palette='Set2')\n",
        "plt.title('One-Way ANOVA: Comparison of Group Means', fontsize=16)\n",
        "plt.xlabel('Groups', fontsize=14)\n",
        "plt.ylabel('Values', fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y67yvnA6ZiRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate random data from a normal distribution\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "# Simulating data for two groups with different means\n",
        "group_A = np.random.normal(loc=20, scale=5, size=50)  # Mean = 20, SD = 5, Sample size = 50\n",
        "group_B = np.random.normal(loc=22, scale=5, size=50)  # Mean =_\n"
      ],
      "metadata": {
        "id": "O6nugR88ZsQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate random data from a normal distribution\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulating sample data (sample size n=30) with a population variance of 25 (std deviation = 5)\n",
        "sample_data = np.random.normal(loc=50, scale=5, size=30)\n",
        "\n",
        "# Hypothesized population variance (H‚ÇÄ: œÉ¬≤ = 25)\n",
        "sigma_0_squared = 25\n",
        "\n",
        "# Calculate sample variance (S¬≤)\n",
        "sample_variance = np.var(sample_data, ddof=1)  # ddof=1 to\n"
      ],
      "metadata": {
        "id": "_28B6tUoZ06U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Write a Python script to perform a Z-test for comparing proportions between two datasets or groups ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate Data for Two Groups\n",
        "# Group 1: 100 successes out of 200 trials\n",
        "# Group 2: 80 successes out of 200 trials\n",
        "\n",
        "successes_1 = 100  # Successes in Group 1\n",
        "n1 = 200          # Sample size of Group 1\n",
        "\n",
        "successes_2 = 80   # Successes in Group 2\n",
        "n2 = 200          # Sample size of\n"
      ],
      "metadata": {
        "id": "kxhcB2NJZ-hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#26.Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate Data for Two Datasets\n",
        "np.random.seed(42)\n",
        "\n",
        "# Dataset 1: Normally distributed data with a smaller variance\n",
        "data1 = np.random.normal(loc=50, scale=5, size=100)\n",
        "\n",
        "# Dataset 2: Normally distributed data with a larger variance\n",
        "data2 = np.random.normal(loc=50, scale=10, size=100)\n",
        "\n",
        "# Step 1: Calculate the sample variances\n",
        "s1_squared = np.var(data1, ddof=1)  # Sample variance for Dataset 1\n",
        "s2_squared = np.var(data2, ddof=1)  # Sample variance for Dataset 2\n",
        "\n",
        "# Step 2: Calculate the F-statistic\n",
        "f_statistic = s1_squared / s2_squared\n",
        "\n",
        "# Step 3: Degrees of freedom\n"
      ],
      "metadata": {
        "id": "zmHU9jruaHUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results ?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate Observed Data\n",
        "# Let's simulate the observed data: number of students in each grade category\n",
        "observed = np.array([30, 50, 40, 60, 20])  # Observed frequencies for grades A, B, C, D, F\n",
        "categories = ['A', 'B', 'C', 'D', 'F']    # Grade categories\n",
        "\n",
        "# Expected Frequencies (Assuming the expected distribution is uniform)\n",
        "total_students = np.sum(observed)\n",
        "expected = np.array([total_students / len(categories)] * len(categories))  # Expected frequencies\n",
        "\n",
        "# Step 1: Perform the Chi-Square Goodness of Fit Test\n",
        "chi2_stat, p_value = stats.chisquare(observed, expected)\n",
        "\n",
        "# Output the results\n",
        "print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Step 2: Interpretation of Results\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: The observed distribution is significantly different from the expected distribution.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: The observed distribution is not significantly different from the expected distribution.\")\n",
        "\n",
        "# Step 3: Visualize the observed and expected frequencies\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Plot observed and expected frequencies\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(categories))\n",
        "\n",
        "bars1 = ax.bar(index, observed, bar_width, label='Observed', color='blue')\n",
        "bars2 = ax.bar(index + bar_width, expected, bar_width, label='Expected', color='orange')\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Grade Category', fontsize=14)\n",
        "ax.set_ylabel('Frequency', fontsize=14)\n",
        "ax.set_title('Chi-Square Goodness of Fit Test', fontsize=16)\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels(categories)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6MQcIAPHaawM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}